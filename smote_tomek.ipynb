{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# px requires nbformat \n",
    "from datasets import load_dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from sortedcontainers import SortedList\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.dates as mdates \n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/Users/cherylsusan/Desktop/data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1990281 entries, 0 to 1990280\n",
      "Data columns (total 34 columns):\n",
      " #   Column                          Dtype  \n",
      "---  ------                          -----  \n",
      " 0   ssn                             object \n",
      " 1   gender                          object \n",
      " 2   state                           object \n",
      " 3   zip                             int64  \n",
      " 4   city_pop                        int64  \n",
      " 5   job                             object \n",
      " 6   category                        object \n",
      " 7   amt                             float64\n",
      " 8   is_fraud                        int64  \n",
      " 9   merchant                        object \n",
      " 10  hour                            int64  \n",
      " 11  day_of_week                     object \n",
      " 12  month                           object \n",
      " 13  trans_quarter                   object \n",
      " 14  year                            int64  \n",
      " 15  age                             int64  \n",
      " 16  city_state                      object \n",
      " 17  prev_trans_fraud                int64  \n",
      " 18  count_fraud_prev10              int64  \n",
      " 19  acc_fraud_count                 int64  \n",
      " 20  merchant_prev_trans_fraud       int64  \n",
      " 21  merchant_count_fraud_prev10     int64  \n",
      " 22  merchant_acc_fraud_count        int64  \n",
      " 23  transaction_risk_score          int64  \n",
      " 24  hourly_risk_score               int64  \n",
      " 25  interval                        float64\n",
      " 26  first_second_purchase           int64  \n",
      " 27  interval_deviation              float64\n",
      " 28  visited_cat                     int64  \n",
      " 29  category_first_second_purchase  int64  \n",
      " 30  amt_deviation                   float64\n",
      " 31  city_population_class           int64  \n",
      " 32  city_fraud_proportion           float64\n",
      " 33  top_city                        int64  \n",
      "dtypes: float64(5), int64(19), object(10)\n",
      "memory usage: 516.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before resampling:\n",
      "is_fraud\n",
      "0    1982985\n",
      "1       7296\n",
      "Name: count, dtype: int64\n",
      "Percentage of fraud cases: 0.37%\n",
      "Original dataset shape: (1990281, 34)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = train_df.drop(['is_fraud'], axis=1) \n",
    "y = train_df['is_fraud']\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Print class distribution before resampling\n",
    "print(\"Class distribution before resampling:\")\n",
    "print(y.value_counts())\n",
    "print(f\"Percentage of fraud cases: {round(y.mean() * 100, 2)}%\")\n",
    "print(f\"Original dataset shape: {train_df.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # Create preprocessing for categorical data\n",
    "# # We'll use OneHotEncoder for categorical features\n",
    "# encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "# X_cat = encoder.fit_transform(X[categorical_features])\n",
    "# # Get the new column names after one-hot encoding\n",
    "# encoded_feature_names = encoder.get_feature_names_out(categorical_features)\n",
    "\n",
    "# # Standardize numerical features\n",
    "# scaler = StandardScaler()\n",
    "# X_num = scaler.fit_transform(X[numerical_features])\n",
    "\n",
    "# # Combine the preprocessed data\n",
    "# X_processed = np.concatenate([X_num, X_cat], axis=1)\n",
    "# # Create a list of all feature names after preprocessing\n",
    "# all_feature_names = numerical_features + encoded_feature_names.tolist()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE-Tomek resampling\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_resampled, y_resampled = smote_tomek.fit_resample(X_processed, y)\n",
    "\n",
    "# Print class distribution after resampling\n",
    "print(\"\\nClass distribution after SMOTE-Tomek:\")\n",
    "print(pd.Series(y_resampled).value_counts())\n",
    "print(f\"Percentage of fraud cases: {round(pd.Series(y_resampled).mean() * 100, 2)}%\")\n",
    "print(f\"Resampled data shape: {X_resampled.shape}\")\n",
    "\n",
    "# Convert the resampled data back to a DataFrame with proper column names\n",
    "# Split the resampled data back into numerical and categorical parts\n",
    "n_numerical = len(numerical_features)\n",
    "X_num_resampled = X_resampled[:, :n_numerical]\n",
    "X_cat_resampled = X_resampled[:, n_numerical:]\n",
    "\n",
    "# Create DataFrames for each part\n",
    "num_df = pd.DataFrame(X_num_resampled, columns=numerical_features)\n",
    "cat_df = pd.DataFrame(X_cat_resampled, columns=encoded_feature_names)\n",
    "\n",
    "# If you need to convert one-hot encoded features back to original categorical features\n",
    "inverse_cat_df = pd.DataFrame()\n",
    "for feature in categorical_features:\n",
    "    # Get all columns related to this feature\n",
    "    cols = [col for col in cat_df.columns if col.startswith(f\"{feature}_\")]\n",
    "    # For each row, find the column with the highest value (or 1 in case of perfect one-hot)\n",
    "    inverse_cat_df[feature] = cat_df[cols].idxmax(axis=1).str.replace(f\"{feature}_\", \"\")\n",
    "\n",
    "# Combine numerical and reconstructed categorical features\n",
    "resampled_df = pd.concat([num_df, inverse_cat_df], axis=1)\n",
    "\n",
    "# Add the target variable\n",
    "resampled_df['is_fraud'] = y_resampled\n",
    "\n",
    "print(f\"Final resampled DataFrame shape: {resampled_df.shape}\")\n",
    "\n",
    "# If you need to save the resampled dataset\n",
    "# resampled_df.to_csv('train_df_resampled.csv', index=False)\n",
    "\n",
    "# The resampled_df can now be used directly for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selectKbest \n",
    "\n",
    "print(\"\\nStep 3: Feature Selection with SelectKBest\")\n",
    "# Choose k - number of features to select (adjust as needed)\n",
    "k = min(30, X_train_resampled.shape[1])  # Select top 30 features or all if fewer\n",
    "selector = SelectKBest(score_func=f_classif, k=k)\n",
    "X_train_selected = selector.fit_transform(X_train_resampled, y_train_resampled)\n",
    "X_test_selected = selector.transform(X_test_processed)\n",
    "\n",
    "# Get selected feature names for interpretation\n",
    "mask = selector.get_support()\n",
    "selected_features = [feature_names[i] for i in range(len(feature_names)) if mask[i]]\n",
    "print(f\"Selected {k} features:\")\n",
    "for i, feature in enumerate(selected_features):\n",
    "    print(f\"{i+1}. {feature}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train Random Forest Classifier\n",
    "print(\"\\nStep 4: Training Random Forest Classifier\")\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=4,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train_selected, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Model Evaluation\n",
    "print(\"\\nStep 5: Model Evaluation\")\n",
    "# Predictions on test set\n",
    "y_pred = rf_model.predict(X_test_selected)\n",
    "y_pred_proba = rf_model.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# Calculate various metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy * 100, 2)}%\")\n",
    "print(f\"ROC AUC Score: {round(auc, 4)}\")\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance Analysis\n",
    "print(\"\\nTop 20 Most Important Features:\")\n",
    "feature_importances = rf_model.feature_importances_\n",
    "indices = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "for i in range(min(20, len(selected_features))):\n",
    "    print(f\"{selected_features[indices[i]]}: {feature_importances[indices[i]]:.4f}\")\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.bar(range(min(20, len(selected_features))), \n",
    "        feature_importances[indices[:20]],\n",
    "        align=\"center\")\n",
    "plt.xticks(range(min(20, len(selected_features))), \n",
    "           [selected_features[i] for i in indices[:20]], \n",
    "           rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
